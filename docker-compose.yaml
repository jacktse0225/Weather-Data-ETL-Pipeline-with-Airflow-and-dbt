version: '3.8'

services:
  db:
    image: postgres:latest
    container_name: weather_db
    environment:
      POSTGRES_DB: mydatabase
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    volumes:
      - db_data:/var/lib/postgresql/data
      - ./sql_database/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"

  postgres:
    image: postgres:latest
    networks:
      - elt_network
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow

  init-airflow:
    image: apache/airflow:latest
    depends_on:
      - postgres
    networks:
      - elt_network
    environment:
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgres+psycopg2://airflow:airflow@postgres/airflow
    command: >
      bash -c "airflow db init &&
               airflow users create --username airflow --password password --firstname John --lastname Doe --role Admin --email admin@example.com" 
  
  webserver:
    build:
      context: .
      dockerfile: Dockerfile
    user: root
    depends_on:
      - postgres
    networks:
      - elt_network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./elt_script:/opt/airflow/elt
      - ./data_import:/opt/airflow/data_import
      - /var/run/docker.sock:/var/run/docker.sock
      - ./app:/app
      - ~/.dbt:/root
      - ./dbt_project:/dbt
    environment:
      - LOAD_EX=n
      - EXECUTOR=Local
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgres+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__WEBSERVER__DEFAULT__USER__USERNAME=airflow
      - AIRFLOW__WEBSERVER__DEFAULT__USER__PASSWORD=password
      - AIRFLOW__WWW_USER_USERNAME=airflow
      - AIRFLOW__WWW_USER_PASSWORD=password
      - AIRFLOW__WEBSERVER__SECRET_KEY=secret
      - API_KEY=${API_KEY}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    ports:
      - "8080:8080"
    command: webserver

  scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    user: root
    depends_on:
      - postgres
    networks:
      - elt_network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./elt_script:/opt/airflow/elt
      - ./data_import:/opt/airflow/data_import
      - /var/run/docker.sock:/var/run/docker.sock
      - ./app:/app
      - ~/.dbt:/root
      - ./dbt_project:/dbt
    environment:
      - LOAD_EX=n
      - EXECUTOR=Local
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgres+psycopg2://airflow:airflow@postgres/airflow
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW__CORE__FERNET_KEY}
      - AIRFLOW__WEBSERVER__DEFAULT__USER__USERNAME=airflow
      - AIRFLOW__WEBSERVER__DEFAULT__USER__PASSWORD=password
      - AIRFLOW__WWW_USER_USERNAME=airflow
      - AIRFLOW__WWW_USER_PASSWORD=password
      - AIRFLOW__WEBSERVER__SECRET_KEY=secret
      - API_KEY=${API_KEY}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    command: scheduler


  dbt:
    image: ghcr.io/dbt-labs/dbt-postgres:1.4.7
    command:
      [
       "run",
       "--profiles-dir",
       "/root",
       "--project-dir",
       "/dbt"
      ]
    networks:
      - elt_network
    volumes:
      - ./dbt_project:/dbt
      - ~/.dbt:/root
    environment:
      DBT_PROFILE: default
      DBT_TARGET: dev
    depends_on:
      - postgres

networks:
  elt_network:
    driver: bridge

volumes:
  db_data:
